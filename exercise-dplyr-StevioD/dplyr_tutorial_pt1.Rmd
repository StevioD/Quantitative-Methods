---
layout: page
title: dplyr Introduction - Part 1
---

```{r options, echo=FALSE,message=F}
library(tidyverse)
library(DBI)
library(scales)
library(bigrquery)
library(lubridate)
```

## What is dplyr?

`dplyr` is a powerful R-package to transform and summarize tabular data 
with rows and columns. For another explanation of dplyr see the 
dplyr package vignette: [Introduction to dplyr](http://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html)

In order to get the code in this notebook to run, you need to 
run the following to install the packages that you might not have. Run this
in your R-Studio console: `install.packages("tidyverse","bigrquery","lubridate", "DBI","scales","RSQLite","dbplyr")`.

Finally, [here's](https://stat545.com/dplyr-intro.html) 
a great resource I found on `dplyr` that might useful. 

## Why Is It Useful?

The package contains a set of functions (or "verbs") that perform common data 
manipulation operations such as filtering for rows, selecting 
specific columns, re-ordering rows, 
adding new columns and summarizing data. Basically, all of the stuff that 
we do in SQL `dplyr` tries to make easy. 

In addition, dplyr contains a useful function to perform another 
common task which is the "split-apply-combine" concept.  We will 
discuss that in a little bit. 

## How Does It Compare To Using Base Functions R?

If you are familiar with R, you are probably familiar with 
base R functions such as split(), subset(), apply(), sapply(), 
lapply(), tapply() and aggregate(). Compared to base functions 
in R, the functions in `dplyr` are easier to work with, 
are more consistent in the syntax and are targeted for 
data analysis around data frames, instead of just vectors. 

## Working with Data

I've included a zip file in this week on Moodle 
with a couple of tab-delimited text files
from Wedge data. (Note, these were made years ago so I don't 
vouch for their accuracy.) Let's read start by 
reading those in and doing some basic manipulations 
with `dplyr`. 

```{r data-input}
owner.prod.d <- read_tsv("20161107_owner_product.txt")
prod.ym.d <- read_tsv("20161107_product_year_month_2014.txt",
                      col_types=cols(
                          upc=col_character()
                          ),
                      na=c("NULL"))

# Use the amazing lubridate package to clean up some dates
owner.prod.d$date_joined <- mdy_hm(owner.prod.d$date_joined)

owner.prod.d %>% head
```

Notice the use of the `%>%` operator. We call this the "pipe" operator,
and you can think of it as pushing the data from one side to the 
other. In this case we "pushed" our data frame, `owner.prod.d`, through
the `head` function, which shows us the first six rows. What we get
out is the same thing as if you just call the function with the
data frame as the argument: 

```{r head-example}
head(owner.prod.d)
```

There are a few other functions that are useful for showing your data:

1. `tail(n=)` = Select the last `n` rows of your data set. 
1. `sample_n(size=)` = Select `size` random rows from your data set.
1. `sample_frac(size=)` = Select a fraction of size `size` from your data set.

# Important dplyr Verbs To Remember

dplyr verbs | Description
--- | ---
`select()` | select columns 
`filter()` | filter rows
`arrange()` | re-order or arrange rows
`mutate()` | create new columns
`summarize()` | summarize values
`group_by()` | allows for group operations in the "split-apply-combine" concept


# dplyr Verbs In Action

The two most basic functions are `select()` and `filter()`, which selects columns and filters rows respectively. 

## Selecting Columns Using `select()`

Select a set of columns: the owner, `Description`, and `date_joined`. 

```{r}
holder <- owner.prod.d %>% 
    select(owner,description,date_joined)
head(holder)
```

To select all the columns *except* a specific column, use the "-" (subtraction) operator (also known as negative indexing):

```{r}
prod.ym.d %>% 
    select(-description) %>% 
    head
```

To select a range of columns by name, use the ":" (colon) operator:

```{r}
owner.prod.d %>% 
    select(upc:organic) %>%
    head
```

To select all columns that start with the character string "d", use the function `starts_with()`:

```{r}
owner.prod.d %>% 
    select(starts_with("d")) %>% 
    head
```

Some additional options to select columns based on a specific criteria include:

1. `ends_with()` = Select columns that end with a character string
2. `contains()` = Select columns that contain a character string
3. `matches()` = Select columns that match a regular expression
4. `one_of()` = Select column names that are from a group of names


## Selecting Rows Using `filter()`

Filter the rows for `owner.prod.d` for owners that joined last 
millennium. We'll take a random sample of 10 of those rows to display.

```{r}
owner.prod.d %>% 
    filter(date_joined < "2000-01-01") %>% 
    sample_n(10)
```

Filter the rows in `owner.prod.d` for owners that joined last 
millennium, shopping in "PRODUCE", who spent more than \$1000 on 
that product. 

```{r}
owner.prod.d %>% 
    filter(date_joined < "2000-01-01",
           dept_name=="PRODUCE",
           total_sales > 1000) %>% 
    sample_n(10)
```

You can use the boolean operators (e.g. >, <, >=, <=, !=, `%in%`) to create 
the logical tests. 

# Other dplyr Verbs In Action

## Arrange Or Re-order Rows Using `arrange()`

To arrange (or re-order) rows by a particular column, such as the 
total spend, list the name of the column you want to arrange the rows by:

```{r}
owner.prod.d %>% arrange(total_sales) %>% head
```

Now we will select some columns from `owner.prod.d`, filter on 
spend, arrange the rows by 
the transactions, and then arrange the rows by total spend. Finally, 
show the head of the final data frame:

```{r}
owner.prod.d %>% 
    select(owner,description,dept_name,total_sales, transactions) %>% 
    filter(100 < total_sales, total_sales < 500) %>% 
    arrange(transactions, total_sales) %>% 
    head
```

## Create New Columns Using `mutate()`

The `mutate()` function will add new columns to the data frame. 
Create a new column `spend_per_trans`, which is the ratio of `total_sales` 
to `transactions`. Let's make that column (temporarily), filter by it,
and look at the biggest values. 


```{r}
owner.prod.d %>% 
    filter(total_sales > 0) %>% 
    mutate(spend_per_trans = total_sales/transactions) %>%
    arrange(desc(spend_per_trans)) %>% 
    head
```

Note that we could have looked at these rows with the largest `spend_per_trans`
by calling `tail`, but I wanted to show you the `desc` function (for "descending")
that's available with arrange. 

You can create many new columns using mutate (separated by commas). Let's
add two. 

```{r}
owner.prod.d %>% 
    mutate(spend_per_trans = total_sales/transactions,
           items_per_trans = total_qty/transactions) %>%
    head

```

These columns aren't permanent. This can be useful if you want to 
make some intermediate columns but not add them to your data. But
if you _do_ want to make them permanently part of the data frame,
you just assign it back to itself. 

```{r}
owner.prod.d <- owner.prod.d %>% 
    mutate(spend_per_trans = total_sales/transactions)

```

## Create summaries of the data frame using `summarize()`

The `summarize()` function will create summary statistics for a given 
column in the data frame such as finding the mean. For example, to 
compute the average spend per transaction, 
apply the `mean()` function to that column.

```{r}
owner.prod.d %>% 
    summarize(mean_spt = mean(spend_per_trans))
```

There are many other summary statistics you could consider such `sd()`, `min()`,
`max()`, `median()`, `sum()`, `n()` (returns the length of vector), `first()`
(returns first value in vector), `last()` (returns last value in vector) and
`n_distinct()` (number of distinct values in vector). 

```{r}
owner.prod.d %>% 
    summarize(mean_spt = mean(spend_per_trans), 
              min_spt = min(spend_per_trans),
              max_spt = max(spend_per_trans),
              total = n())
```


## Group operations using `group_by()`

Now things get super cool. The `group_by()` verb is an important function 
in dplyr. As we mentioned before it's related to concept 
of "split-apply-combine". We literally want to split the 
data frame by some variable (e.g. department), apply a function 
to the individual data frames and then combine the output.   

Let's do that: split the `owner.prod.d` data frame by the department name, 
then ask for the same summary statistics as above. We expect a set of summary
statistics for each department order. As a bonus, let's arrange by average
transaction size.

```{r}
owner.prod.d %>% 
    group_by(dept_name) %>% 
    summarize(mean_spt = mean(spend_per_trans), 
              min_spt = min(spend_per_trans),
              max_spt = max(spend_per_trans),
              total = n()) %>% 
    arrange(mean_spt)

```

Pretty cool, right? 

